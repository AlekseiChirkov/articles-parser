Название: Apache Spark: оптимизация производительности на реальных примерах

Автор: valexv

Дата: 2021-09-18, 01:29

Теги: Блог компании Neoflex, Apache *, Big Data *, Хранилища данных *, Data
Engineering *

Контент: Apache Spark – фреймворк для обработки больших данных, который давно
уже стал одним из самых популярных и часто встречаемых во всевозможных
проектах, связанных с Big Data. Он удачно сочетает в себе скорость
работы и простоту выражения своих мыслей разработчиком. Разработчик
работает с данными на достаточно высоком уровне и, кажется, что нет
ничего сложного в том, чтобы, например, соединить два набора данных,
написав всего одну строку кода. Но только задумайтесь: что происходит
в кластере при соединении двух наборов данных, которые могут и не
находится целиком на каком-либо из узлов кластера? Обычно Spark со
всем справляется быстро, но иногда, а особенно, если данных
действительно много, необходимо все-таки понимать – что происходит
уровнем ниже и использовать это знание, чтобы помочь Spark работать в
полную силу.