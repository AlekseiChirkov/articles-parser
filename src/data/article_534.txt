Название: Готовим нестандартные данные для нейросети

Автор: NewTechAudit

Дата: 2021-09-23, 11:51

Теги: Python *, Программирование *, Машинное обучение *

Контент: Сталкивались ли вы когда-либо с проблемой в обучении нейросетей, когда
датасет слишком большой, чтобы загрузить его в оперативную память
полностью и программа выдает Out-of-Memory Error? Например, при
обучении классификатора изображений, у нас нет возможности загрузить
все картинки в память до обучения. Даже если это и возможно для
игрушечных наборов данных, в реальных задачах объёмы данных измеряются
в сотнях, тысячах гигабайт. И мы не можем использовать лишь часть
датасета, так как качество обученной модели тоже упадёт. Конечно, у
нас есть возможность использовать готовые инструменты (например
ImageDagaGenerator в библиотеке Tensorflow), но такой подход работает
только если у нас стандартные данные, такие как папки с файлами
jpg/png или csv файлы.  А что делать, если у нас несколько различных
типов данных (например, входные данные - это изображения и их
текстовое описание), или большое количество табличных данных, где,
например, каждый файл это данные за один день? В этих случаях для
загрузки и подготовки данных на вход модели придётся писать свой
собственный генератор данных.В данной статье я детально расскажу, как
я создавал свой DataGenerator в Kaggle соревновании по определению
наличия опухоли головного мозга по МРТ.Итак, посмотрим на данные,
которые нам предоставили. Для обучения у нас имеется 585 примеров.
Каждый пример представляет собой МРТ скан в четырех режимах: Fluid
Attenuated Inversion Recovery (FLAIR), T1-weighted pre-contrast (T1w),
T1-weighted post-contrast (T1Gd), T2-weighted (T2). Скан в каждом
режиме представляет собой набор одноканальных изображений в формате
DICOM. Возьмем один из примеров и посмотрим разрешение и количество
файлов для каждого режима: