Название: Как принципы ResponsibleAI помогают ML-моделям работать по максимуму?

Автор: kostyakova

Дата: 2021-09-14, 15:14

Теги: Блог компании Первая грузовая компания (ПГК), Машинное обучение *

Контент: С помощью ML-моделей сегодня выдают кредиты, регулируют движение на
дорогах, определяют цены на товары и многое другое. Однако, процесс их
разработки и вывода в продуктивную среду сложен и полон подводных
камней. Очень часто качество прогноза, основанного на реальных данных,
не соответствует ожиданиям пользователей. Меня зовут Надежда
Костякова, я руковожу управлением анализа данных и машинного обучения
в Первой грузовой компании (ПГК). В статье расскажу о принципах,
которым следует наша команда Data Science, чтобы гарантировать
надежную работу алгоритмов машинного обучения в продуктивной
среде.Какие проблемы возникают при использовании ML-моделей? В 2013
году на площадке Kaggle было запущено соревнование. Его участники
должны были отличить звук, издаваемый китом, от остальных звуков.
Запуск прошел нормально, и люди начали загружать свои результаты. Один
из них поразил организаторов: он был сильно выше ожидаемого и достигал
невероятного показателя 0,99 ROC AUC. Как выяснилось, результат этот
был достигнут даже без чтения звуковых файлов. Что же
произошло?Оказалось, что файлы с записью китов отличались по
продолжительности от остальных, имели другой формат даты и были
сгруппированы по времени. Организаторы и участники столкнулись с
проблемой Data Leakage – когда не основные данные, а метаинформация
помогла достичь результата. Это огромная проблема при использовании
модели в «проде»: в реальных условиях у модели не будет таких
метаданных, и ее результат будет крайне низким. В бизнесе это может
привести к значительному экономическому ущербу.