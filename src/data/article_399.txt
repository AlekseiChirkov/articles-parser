Название: Гид по предварительной обработке текста с помощью BERT

Автор: GetMeIT

Дата: 2021-09-25, 16:32

Теги: Машинное обучение *, Natural Language Processing *

Контент: Современные NLP-приложения, например, для анализа настроения, поиска
ответов на вопросы, смарт-ассистенты и т. п., используют огромное
количество данных. Такой объём данных можно напрямую передать в модель
машинного обучения. Почти все текстовые приложения требуют большой
предварительной обработки текстовых данных — создания вложенных
векторов с нуля с использованием счётчика частоты слов. На это уходит
много сил и времени. Чтобы избежать этого, для всех сложных задач
предварительной обработки используются модели Transfer Learning. Им
нужно просто передать необработанный текст, об остальном модель
позаботится сама.Небольшая ремарка. Данный материал является
переводом, и мы не несем ответственности за факты, представленные
автором в первоисточнике.Ключевая тенденция рынка чат-ботов — это
работа над эффективностью в определении намерений пользователя. Для
себя мы поставили данную задачу во главе узла: нам критически важно
сделать продукт удобным и практичным именно для разработчиков. Поэтому
мы сейчас думаем о том, чтобы внедрить BERT в нашу работу. Технология
для нас новая, мы читаем и переводим очень много информации по данному
вопросу. Наиболее интересными материалами мы поделимся с вами в рамках
данного блога.В этой статье мы обсудим один из фреймворков
трансферного обучения — BERT. Рассмотрим, как использовать модуль
предварительной обработки BERT, чтобы создавать вложения слов без
усилий. Основные моменты, которые будут рассмотрены в этой статье...